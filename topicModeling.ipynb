{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will serve as the notebook for testing my topic modeling portion of this project.\n",
    "\n",
    "After verifying that everything is working, it will be changed to a .py file to be runnable on new incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from tmtoolkit.corpus import Corpus, filter_clean_tokens, corpus_num_tokens, vocabulary_size, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data/2014_funny_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>HOUR_int</th>\n",
       "      <th>DAY_int</th>\n",
       "      <th>MONTH_int</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ain't no half steppin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Inside the gas tank cover or on top of a tire</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Brought to you by /r/SummerReddit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>This makes me want to murder.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>I know someone who got a DUI sleeping it off i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               body  HOUR_int  \\\n",
       "0      1                              Ain't no half steppin         0   \n",
       "1      7      Inside the gas tank cover or on top of a tire         0   \n",
       "2     12                  Brought to you by /r/SummerReddit         0   \n",
       "3      1                     This makes me want to murder.          0   \n",
       "4      3  I know someone who got a DUI sleeping it off i...         0   \n",
       "\n",
       "   DAY_int  MONTH_int  flag  \n",
       "0        1          1  okay  \n",
       "1        1          2  okay  \n",
       "2        1          7  okay  \n",
       "3        1          5  okay  \n",
       "4        1          2  okay  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df.body.isnull()]  # Remove the missed null values\n",
    "\n",
    "conditions = [ (df['score'] < 1), (df['score'] >= 1) & (df['score'] <= 13), (df['score'] > 13) ] \n",
    "values = ['bad', 'okay', 'good']\n",
    "df['flag'] = np.select(conditions, values)  # Bin our scores into categories under the column name 'flag'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df.body)  # Get full corpus of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    corp = Corpus({ i:r for i, r in enumerate(texts) })\n",
    "    # preproc = TMPreproc(corp, language='en')\n",
    "    # preproc.pos_tag()  # If we want to filter for POS later\n",
    "    preproc.lemmatize()\n",
    "    preproc.tokens_to_lowercase()\n",
    "    preproc.remove_special_chars_in_tokens()\n",
    "    preproc.add_stopwords(['http']) # Start with just http, will add more as we go if we want to go more in-depth\n",
    "    # preproc.filter_for_pos('N', 'V', 'ADJ')  # Can filter for POS if we want to later\n",
    "    preproc.clean_tokens(remove_numbers = True, remove_shorter_than = 2)\n",
    "    preproc.remove_common_tokens(df_threshold=0.75)  # If token in >75% of corpi, delete\n",
    "    preproc.remove_uncommon_tokens(df_threshold=0.01)  # If token in <1% of corpi, delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zade\\anaconda3\\envs\\py1010-red\\lib\\site-packages\\catalogue\\__init__.py:123: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "language model \"en_core_web_sm\" cannot be loaded; are you sure it is installed? see https://spacy.io/models or https://tmtoolkit.readthedocs.io/en/latest/install.html for further information on installing language models",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m smallcorp \u001b[39m=\u001b[39m Corpus(corpus[:\u001b[39m1000\u001b[39;49m], language\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Zade\\anaconda3\\envs\\py1010-red\\lib\\site-packages\\tmtoolkit\\corpus\\_corpus.py:210\u001b[0m, in \u001b[0;36mCorpus.__init__\u001b[1;34m(self, docs, language, language_model, load_features, add_features, raw_preproc, spacy_token_attrs, spacy_instance, spacy_opts, punctuation, max_workers, workers_timeout)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39m# model meta information\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m language_model \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m spacy\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mget_installed_models():\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlanguage model \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlanguage_model\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m cannot be loaded; are you sure it is installed? \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    211\u001b[0m                        \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msee https://spacy.io/models or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    212\u001b[0m                        \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://tmtoolkit.readthedocs.io/en/latest/install.html for further information \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    213\u001b[0m                        \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mon installing language models\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    215\u001b[0m model_info \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39minfo(language_model)\n\u001b[0;32m    217\u001b[0m \u001b[39m# the default pipeline compenents for SpaCy language models â€“ these would be loaded *and enabled* if not\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m# explicitly excluded\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: language model \"en_core_web_sm\" cannot be loaded; are you sure it is installed? see https://spacy.io/models or https://tmtoolkit.readthedocs.io/en/latest/install.html for further information on installing language models"
     ]
    }
   ],
   "source": [
    "smallcorp = Corpus(corpus[:1000], language='en')  # For testing\n",
    "# smallcorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.tokens_datatable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py0913-red",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
